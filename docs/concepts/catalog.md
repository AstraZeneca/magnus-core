Catalog provides a way to store and retrieve data generated by the individual steps of the dag to downstream
steps of the dag. It can be any storage system that indexes its data by a unique identifier.

For example, a local directory structure partitioned by a ```run_id``` or S3 bucket prefixed by ```run_id```.

!!! info inline end "Structure"

    In the strictest sense, the directory structure is same as the directory structure of any individual task.

    This distinction is important when every step is a [```shell``` task](../task/#shell) that operate in
    different execution contexts like containers.


The directory structure within a partition is the same as the project directory structure. This enables you to
get/put data in the catalog as if you are working with local directory structure. Every interaction with the catalog
(either by API or configuration) results in an entry in the [```run log```](../run-log/#step_log)

Internally, magnus also uses the catalog to store execution logs of tasks i.e stdout and stderr from
[python](../task/#python) or [shell](../task/#shell) and executed notebook from [notebook tasks](../task/#notebook).

Since the catalog captures the data files flowing through the pipeline and the execution logs, it enables you
to debug failed pipelines or keep track of data lineage.


!!! warning "Storage considerations"

    Since the data is stored per-run, it might cause the catalog to inflate.

    Please consider some clean up
    mechanisms to regularly prune catalog for executions that are not relevant.


### Compute data folder

The directory structure of the catalog for an execution of the pipeline resembles the project
directory structure. compute data folder provides a handy way to provide a default directory
for the project data.

The default location of the ```compute_data_folder``` within magnus is the ```data``` folder. This can be overridden either at [global level](../../configurations/catalog) or
per task level by configuration.


## Example


=== "Configuration"

    Below is a sample configuration that uses the local file system as a catalog store.
    The default location of the catalog is ```.catalog``` and is configurable.

    Every execution of the pipeline will create a sub-directory of name ```run_id``` to store the artifacts
    generated from the execution of the pipeline.

    ```yaml
    --8<-- "examples/configs/fs-catalog.yaml"
    ```

    1. Use local file system as a central catalog, defaults to ```.catalog```
    2. By default, use ```data``` folder as the location of users content but we override it
    globally to "."

=== "python sdk"

    ```python
    --8<-- "examples/concepts/catalog.py"
    ```

=== "yaml"

    ```yaml
    --8<-- "examples/concepts/catalog.yaml"
    ```




Resulting directory structure and ```run log```.

=== "Directory structure"


=== "Run log"




## Configuration within Step

Within a step of the dag, the catalog can be configured by

```yaml
catalog:
  ...

dag:
  steps:
    step name:
      ...
      catalog:
        compute_data_folder: # optional
        get:
          - list
        put:
          - list

    ...
```

or via the Python SDK:

```python
from magnus import Task

catalog = {
  'compute_data_folder': '' #Â point to the directory from where the data should be extracted
  'get': [], # All the files to get from the catalog
  'put': [] # All the files to put in the catalog
}

first = Task(name='Cool function', command='my_module.my_cool_function', catalog=catalog)

```

### compute_data_folder

The ```compute_data_folder``` for a single step could be different from the global ```compute_data_folder```
and you can provide it by using the catalog settings for that step.

The actual cataloging is done in two stages:

- get: Get the data mentioned in the ```get``` from the catalog to ```compute_data_folder``` before executing the node.
- put: Store all the data mentioned in ```put``` from the ```compute_data_folder``` to catalog after executing the node.

Both ```get``` and ```put``` can accept glob patterns. Internally we use
[Pathlib match function](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.match)
to match the name to pattern.

---
!!! Note

    The ```put``` stage of the cataloging checks if the data source has been obtained from ```get``` phase and
    only puts a new record if there were changes observed during the execution of the node.
---

## Interaction within code

You can also interact with the catalog within your python programs if it is convenient than providing it in yaml.

--8<-- [start:how-do-i-pass-data]

### Get from catalog

To get a file from the catalog, use ```get_from_catalog``` from magnus.

For example, the below code gets the file ```interesting_data.csv``` from the catalog into ```data/``` folder.


```python
from magnus import get_from_catalog

def my_function():
  get_from_catalog('interesting.csv', destination_folder='data/')

```

### Put in catalog

To put a file into the catalog, use ```put_in_catalog``` from magnus.

For example, the below code puts the file ```data/interesting_data.csv``` from the data folder into catalog.


```python
from magnus import put_in_catalog

def my_function():
  put_in_catalog('data/interesting.csv')

```

---
!!! Note

    Unlike ```put``` phase of the cataloging process, put_in_catalog does not check if the cataloging object has
    changed and does a blind update.

---

--8<-- [end:how-do-i-pass-data]

## Passing Data Objects

--8<-- [start:how-do-i-pass-objects]

While the is good for files, it is inconvenient to dump and load the object into files for the cataloging to happen.
Magnus provides utility functions to make it easier.

### Get object from catalog

To get a object from the catalog, use ```get_object``` from magnus.

For example, the below code gets a pandas dataframe from previous steps, called ```interesting_data``` from the catalog.


```python
from magnus import get_object

def my_function():
  df = get_object("interesting_data")

```

Be aware that, the function would raise an exception if ```interesting_data``` was not added to catalog before.

### Put object in catalog

To put a object into the catalog, use ```put_object``` from magnus.

For example, the below code puts the dataframe ```interesting_data``` into the catalog as ```interesting_data.pickle```.


```python
from magnus import put_object

def my_function():
  put_object(data=interesting_data, name="interesting_data")

```

---
!!! Note

    We internally use pickle for the serialization and deserialization. Please raise a feature request if you need
    other kind of serializers.

---

--8<-- [end:how-do-i-pass-objects]

## Parameterized definition

As with any part of the magnus configuration, you can parameterize the configuration of catalog to switch between
catalog providers without changing the base definition.

Please follow the example provided [here](../dag/#parameterized_definition) for more information.


## Extensions

You can easily extend magnus to bring in your custom provider, if a default
implementation does not exist or you are not happy with the implementation.

[Extensions are being actively developed and can be found here.](https://github.com/AstraZeneca/magnus-extensions)

The ```BaseCatalog``` implementation is as follows:

```python
# You can find the source code in magnus/catalog.py
--8<-- "magnus/catalog.py:docs"

```


The custom extensions should be registered as part of the namespace: ```catalog``` for it to be
loaded.

```toml
# For example, as part of your pyproject.toml
[tool.poetry.plugins."catalog"]
"gfs" = "YOUR_PACKAGE:GFStorage"
```
